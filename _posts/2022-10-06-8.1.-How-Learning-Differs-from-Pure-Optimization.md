---
title: "[DL Book] 8.1. How Learning Differs from Pure Optimization"
categories:
  - Deep Learning Book
tags:
  - Books
  - Deep Learning Book
  - Optimization
  - Statistics
  - Study Group
---

# 8.1. 일반적인 최적화와의 차이

머신러닝에 사용되는 최적화가 일반적인 최적화와 다른 가장 큰 부분은 최적화가 **간접적으로 작용한다**는 것이다. 

- 일반적인 최적화에서는 주어진 함수를 최소화하는 문제 그 자체를 목적으로 한다.
- 반면 머신러닝에서의 최적화는 **Training set에 대한 함수** $J(\theta)$의 최솟값을 찾는 것으로, **Test set에 대한 평가지표** $P$를 높이는 것을 목표로 한다.

학습 데이터셋에 대한 손실함수 $J(\theta)$는 다음과 같이 적을 수 있다.

$$
J(\theta) = \mathbb{E}_{(\boldsymbol x, y)\sim\hat{p}_{data}}L(f(\boldsymbol x; \theta), y)\hspace{1cm}\text{Cost Function w.r.t. Training set}
$$

>
> :bulb: **Notation\
> $J(\theta)$ : 학습 데이터셋에 대한 손실함수**\
> $L$ : 단일 데이터에 대한 손실함수\
> $\hat{p}_{data}$ : 관측된 Training set의 분포\
> $x$ : 입력값\
> $y$ : 출력값\
> $\theta$ : 모델 파라미터

이제 전체(학습+테스트) 데이터셋에 대한 손실함수 $J^\ast(\theta)$를 다음과 같이 적을 수 있다.

$$
J^\ast(\theta) = \mathbb{E}_{(\boldsymbol x,y)\sim p_{data}}L(f(\boldsymbol x;\theta), y) \hspace{1cm}\text{Cost Function w.r.t. Full Dataset}
$$

> :bulb: **Notation\
> $J^\ast(\theta)$ : 전체(학습+테스트) 데이터셋에 대한 손실함수**\
> $p_{data}$ : 실제 Training set  + Test set 데이터의 분포

### 1.1. Empirical Risk Minimization

머신러닝에서 해결하고자 하는 최적화 문제는 일반적으로 위 절에서 보여지는 두 번째 수식의 최소화이다. 이 수식이 나타내는 값을 **Risk(위험)**라고 부른다. 첫 번째 수식이 나타내는 값은 관측된 데이터 $\hat{p}_{data}$를 기반으로 하므로 **Empirical Risk(관측된 위험)**라고 부른다.

재미있는 것은 실제 데이터의 분포 $p_{data}$는 우리가 절대로 알 수 없다는 것이다. 만약 $p_{data}$가 알려져 있다면, 이것은 간단히 해결할 수 있는 최적화 문제가 된다. 하지만 $p_{data}$가 알려져 있지 않고 그 부분집합 $\hat{p}_{data}$가 주어진다면, 머신러닝 문제가 된다.

머신러닝 문제도 최적화 문제처럼 해결할 수 있다. Empirical Risk를 최소화함으로써 Risk도 함께 줄어들 것을 기대하고, 첫 번째 수식을 최소화하는 것이다. 이러한 전략을 Empirical Risk Minimization이라고 부른다.

$$
\mathbb{E}_{\boldsymbol x, y\sim\hat{p}_{data}(\boldsymbol x, y)}\big[L(f(\boldsymbol x; \theta), y)\big]=\frac{1}{m}\sum^m_{i=1}L(f(\boldsymbol x^{(i)};\theta),y^{(i)}) \hspace{1cm} \text{Empirical Risk}
$$

> 
> :bulb: **Notation**\
> $m$ : 데이터셋의 샘플 수

중요한 것은 Empirical Risk를 최소화함으로써 Risk가 같이 줄어들도록 문제를 정의하는 것이다. 이를 충족시키기 위한 몇 가지 이론적인 조건들에 대해서는 별도의 연구가 존재한다.

단, Empirical Risk Minimization에는 몇 가지 위험성이 존재한다.

- 과적합(Overfitting)의 위험이 있다.
- 현대의 최적화는 경사하강법(Gradient Descent)에 다수 의존하는데, 모든 손실함수가 Gradient를 가지는 것은 아니다.

이러한 단점들 탓에 Empirical Risk Minimization은 머신러닝 문제를 푸는 데에 있어서 **사실상 부적절한 전략**이다. 앞으로 살펴볼 전략들에서는 “실제로 최적화하는 값”과 우리가 “최적화의 목적으로 두는 값” 사이의 간극이 더 클 것이다.

### 1.2. 대리 손실함수와 학습 조기종료

현실에는 우리가 실제로 관심있는 손실함수가 최적화하기에 부적절한 경우가 있다. 대표적으로는 **0-1 손실함수(Zero-One Loss)**가 그렇다. 이런 경우 해당 손실함수 대신 수학적인 최적화가 용이한 **대리 손실함수(Surrogate Loss Function)**를 정의하여 대신 최적화하는 전략이 있다. 예를 들면 위에서 말한 0-1 손실함수의 경우 **음의 로그 가능도함수(Negative Log Likelihood, NLL)**를 대리 손실함수로 삼을 수 있다.

대리 손실함수를 사용함으로써 더 정확한 학습이 가능할 때도 있다. 경사하강법을 이용해 NLL을 최적화하면서 0-1 손실함수의 값을 추적해 보면, 0-1 손실함수가 0이 되었음에도 불구하고 NLL은 계속해서 감소하는 것을 알 수 있을 것이다.

마지막으로, 학습 알고리즘에서의 최적화가 일반적인 최적화와 다른 중요한 점 하나는 바로 학습 조기종료에 있다. 머신러닝 문제에서는 최적화 문제와 다르게 과적합이라는 적이 존재하므로, **검증 데이터셋(Validation set)**과 학습 조기종료를 이용해 과적합이 일어나기 전에 알고리즘을 종료하는 것이 중요하다. 이것은 일반적인 최적화 문제에서 오직 Gradient가 0에 가까워졌을 때만 알고리즘이 종료되는 것과 상반된다.