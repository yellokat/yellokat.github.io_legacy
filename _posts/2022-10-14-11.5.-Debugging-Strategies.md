---
title: "[DL Book] 11.5. Debugging Strategies"
categories:
  - Deep Learning Book
tags:
  - Books
  - Deep Learning Book
  - Debugging
  - Study Group
---

머신러닝 시스템이 잘 작동하지 않는 원인을 파악하는 것은 어려운 작업이다. 사실, 머신러닝을 통한 문제 해결 자체가, **인간이 쉽게 포착하지 못하는 부분까지 알고리즘에게 맡기는 것**이 의의이기에, 인간의 눈으로 무엇이 잘못되었는지 알기 어려운 것은 **당연하다**. 머신러닝 시스템의 디버깅에는 크게 두 가지의 난점이 있다. 

- 주어진 입력값에 대해 어떤 출력을 내는 것이 “정상”인지 알 수 없다.
- 머신러닝 시스템의 여러 부분 중에서 한 부분이 잘못되어도, 다른 부분은 그에 맞추어 적응하기 때문에, 출력값을 조사하는 것만으로는 내부적인 오류를 알아내기 어렵다.

심층신경망을 디버깅할 때는 이러한 난점을 적어도 하나 이상 타파할 수 있는 전략이 사용된다.

### 추론 결과 확인하기

매우 당연한 일이지만 간과하기 쉽다. 모델의 출력값을 잘 살피고 제대로 된 추론을 하고 있는지 확인하는 것이다. 예를 들면 음성 생성 모델(Generative Model of Speech)의 경우 실제로 생성된 음성을 들어 보고 적절한지 판단할 수 있다. 객체 분할(Image Segmentation)의 경우 원본 데이터셋과 세그멘테이션 결과를 나란히 시각화해, 추론이 잘 진행되었는지 판단할 수 있다.

중요한 것은 **하나의 숫자에 불과한 평가 지표에 과도하게 의존하지 않는 것**이다. 평가 지표는 개선되는 것처럼 보이지만 추론은 엉터리인 경우가 존재하기 때문이다.

### 최악의 결과 확인하기

모델이 특정 입력값에 대해 나쁜 퍼포먼스를 보인다면, 왜 그런지 파악하려고 시도하는 것이 중요하다. 모델이 가장 잘못된 추론을 내놓는 입력값들을 모아 놓고 살펴보라. 예를 들면 전처리 방식이 잘못되었다는 것을 확인하게 될지도 모른다.

### 코딩 실수 확인하기

각종 라이브러리의 사용 방식, 함수의 작동 방식을 잘못 숙지하고 있지는 않은지 확인하라. 흔한 실수로는 평가 지표의 산출방식, 오차 계산 과정에서의 실수 등이 있다.

### 매우 작은 데이터셋으로 학습하기

학습 데이터셋에 대해 오차가 잘 줄어들지 않는다면, 정말로 모델의 수용력이 부족해서 언더피팅이 발생하는 것인지, 아니면 코드에 문제가 있는 것인지 확인할 필요가 있다. 아무리 간단한 모델이라도 매우 작은 학습 데이터셋이라면 충분히 학습할 수 있다.

따라서 1~2 개의 샘플로 구성된 데이터셋으로 모델을 학습시켜 보고, 이에 대해 모델을 오버피팅시킬 수 있는지 확인해 보는 것이 좋다. 모델이 단 하나의 샘플에도 과적합할 수 없다면, 당신의 코드 혹은 라이브러리의 코드에 결함이 있을 가능성이 매우 높다.

### 그래디언트 분석하기

자동으로 역전파를 진행해주는 라이브러리를 사용하지 않을 경우에는 스스로 그래디언트를 계산해서 직접 가중치를 업데이트해 주어야 할 때가 있다. 이 경우, 그래디언트에 해당하는 수식을 잘못 작성해 학습이 제대로 진행되지 않는 경우가 있다. 따라서 **정확한 그래디언트로 작업하고 있는지를 확인**하는 과정이 유용할 수 있다.

### 그래디언트와 활성화 함수 시각화하기

심층신경망 내부에서 활성화 함수에 의해 입력값이 특정 값으로 수렴하는 것은 딥러닝의 오래된문제였다. 예를 들면 ReLU를 거친 값의 대부분이 0이 된다거나, tanh를 거친 값의 대부분이 1 혹은 -1이 되어 버리는 경우, 원활한 학습이 불가능하다. 이을 지속적으로, 일반적으로 1에폭 정도 모니터링하여 신경망이 과도하게 포화(Saturate)되지 않도록 조절하는 것이 중요하다. 

예를 들면 tanh의 경우, 활성화 함수를 거치기 직전 값들을 살펴보자. 이 값들의 **절댓값의 평균**은 해당 활성화 함수가 포화된 정도를 가리키는 지표가 된다. 비슷하게, ReLU의 경우, 활성화 함수를 거치기 직전 값들 중 음수인 값들의 비율이 유사한 지표의 역할을 한다.

마지막으로 한 번의 파라미터 업데이트로 가중치가 얼마나 많이 변화하는지 살펴보는 것도 좋다. 가중치는 미니배치 업데이트 시마다 기존 값에서 1% 정도 변화하는 것이 바람직하다.

### 최적화 알고리즘의 해석학적 제약

일부 고급 최적화 알고리즘에서는 어떤 특별한 성질이 보장되는 경우가 있다. 예를 들면 매 업데이트마다 목적함수를 반드시 감소시키는 성질의 학습 알고리즘이 있다. 또 다른 예시로 그래디언트의 특정 값들을 반드시 0으로 보내는 성질을 띠는 것도 있다.

이렇듯 다양한 특징이 보장되는 최적화 알고리즘을 사용한다면, 각 단계에서 이 제약을 벗어나는 가중치 갱신이 이루어지지는 않는지 살펴보면 도움이 될 수 있다. 물론, 컴퓨터는 정확한 해석학적 계산이 불가능하므로 매우 작은 수치의 오차는 허용해야 한다.