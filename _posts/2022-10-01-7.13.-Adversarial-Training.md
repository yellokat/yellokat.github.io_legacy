---
title: "[DL Book] 7-13. Adversarial Training"
categories:
  - Deep Learning Book
tags:
  - Books
  - Deep Learning Book
  - Regularization
  - Statistics
  - Study Group
---

# 7.13. 적대적 훈련
최근 심층신경망은 일부 작업에서 인간의 오차율을 따라잡기 시작했다. 하지만 정말로 심층신경망이 인간 수준의 이해력을 가지고 있을까? **적대적 공격(Adversarial Attack)**은 인간의 눈으로는 일반적인 데이터와 구분할 수 없는 입력으로 심층신경망을 교묘하게 속일 수 있다. 

![위 예시에서 사전 학습된 GoogLeNet 이미지 분류기는 첫 번째 사진을 “판다”라고 분류했다. 하지만 언뜻 비슷해 보이는, 노이즈가 주입된 세 번째 사진은 전혀 다른 “원숭이”로 분류했다.](/assets/images/dlbook/7/9.png)

위 예시에서 사전 학습된 GoogLeNet 이미지 분류기는 첫 번째 사진을 “판다”라고 분류했다. 하지만 언뜻 비슷해 보이는, 노이즈가 주입된 세 번째 사진은 전혀 다른 “원숭이”로 분류했다.

이러한 공격에 대응하는 방법 중 가장 단순한 것은 **적대적 공격에 쓰일 만한 데이터를 만들어서 학습에 사용하는 것이다.** 이것을 **적대적 훈련(Adversarial Training)**이라고 한다.